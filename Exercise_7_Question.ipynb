{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb のコピー",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santolina/Convolutional-Neural-Networks-in-TensorFlow/blob/master/Exercise_7_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "4a1b04f0-9efb-4c6d-9e8c-de0c0f514413"
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b719495-3e51-48c7-f1fa-47186c2d4fad"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), include_top=False, weights = None)\n",
        "\n",
        "# Your Code Here\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  # Your Code Here\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-31 14:40:25--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 2607:f8b0:400c:c15::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  57.5MB/s    in 1.5s    \n",
            "\n",
            "2019-10-31 14:40:27 (57.5 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d94d5c8-bb28-46e1-dfce-155d5a76b634"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer(\"mixed7\")\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output # Your Code Here\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e76f7e10-552f-42f5-b455-188edd871188"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(rate=0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = \"binary_crossentropy\", \n",
        "              metrics = [\"acc\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         38536192    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "a5b3b8fb-63d7-441a-b0c9-4f43a7c25772"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()\n",
        "\n",
        "%ls /tmp/validation/humans"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-31 14:50:41--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 2607:f8b0:400c:c12::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   123MB/s    in 1.2s    \n",
            "\n",
            "2019-10-31 14:50:43 (123 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-10-31 14:50:44--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 2607:f8b0:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-10-31 14:50:44 (184 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n",
            "valhuman01-00.png  valhuman02-07.png  valhuman03-14.png  valhuman04-21.png\n",
            "valhuman01-01.png  valhuman02-08.png  valhuman03-15.png  valhuman04-22.png\n",
            "valhuman01-02.png  valhuman02-09.png  valhuman03-16.png  valhuman04-23.png\n",
            "valhuman01-03.png  valhuman02-10.png  valhuman03-17.png  valhuman04-24.png\n",
            "valhuman01-04.png  valhuman02-11.png  valhuman03-18.png  valhuman05-00.png\n",
            "valhuman01-05.png  valhuman02-12.png  valhuman03-19.png  valhuman05-01.png\n",
            "valhuman01-06.png  valhuman02-13.png  valhuman03-20.png  valhuman05-02.png\n",
            "valhuman01-07.png  valhuman02-14.png  valhuman03-21.png  valhuman05-03.png\n",
            "valhuman01-08.png  valhuman02-15.png  valhuman03-22.png  valhuman05-04.png\n",
            "valhuman01-09.png  valhuman02-16.png  valhuman03-23.png  valhuman05-05.png\n",
            "valhuman01-10.png  valhuman02-17.png  valhuman03-24.png  valhuman05-06.png\n",
            "valhuman01-11.png  valhuman02-18.png  valhuman04-00.png  valhuman05-07.png\n",
            "valhuman01-12.png  valhuman02-19.png  valhuman04-01.png  valhuman05-08.png\n",
            "valhuman01-13.png  valhuman02-20.png  valhuman04-02.png  valhuman05-09.png\n",
            "valhuman01-14.png  valhuman02-21.png  valhuman04-03.png  valhuman05-10.png\n",
            "valhuman01-15.png  valhuman02-22.png  valhuman04-04.png  valhuman05-11.png\n",
            "valhuman01-16.png  valhuman02-23.png  valhuman04-05.png  valhuman05-12.png\n",
            "valhuman01-17.png  valhuman02-24.png  valhuman04-06.png  valhuman05-13.png\n",
            "valhuman01-18.png  valhuman03-00.png  valhuman04-07.png  valhuman05-14.png\n",
            "valhuman01-19.png  valhuman03-01.png  valhuman04-08.png  valhuman05-15.png\n",
            "valhuman01-20.png  valhuman03-02.png  valhuman04-09.png  valhuman05-16.png\n",
            "valhuman01-21.png  valhuman03-03.png  valhuman04-10.png  valhuman05-17.png\n",
            "valhuman01-22.png  valhuman03-04.png  valhuman04-11.png  valhuman05-18.png\n",
            "valhuman01-23.png  valhuman03-05.png  valhuman04-12.png  valhuman05-19.png\n",
            "valhuman01-24.png  valhuman03-06.png  valhuman04-13.png  valhuman05-20.png\n",
            "valhuman02-00.png  valhuman03-07.png  valhuman04-14.png  valhuman05-21.png\n",
            "valhuman02-01.png  valhuman03-08.png  valhuman04-15.png  valhuman05-22.png\n",
            "valhuman02-02.png  valhuman03-09.png  valhuman04-16.png  valhuman05-23.png\n",
            "valhuman02-03.png  valhuman03-10.png  valhuman04-17.png  valhuman05-24.png\n",
            "valhuman02-04.png  valhuman03-11.png  valhuman04-18.png  valhuman05-25.png\n",
            "valhuman02-05.png  valhuman03-12.png  valhuman04-19.png  valhuman05-26.png\n",
            "valhuman02-06.png  valhuman03-13.png  valhuman04-20.png  valhuman05-27.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d3dd68c8-17be-4511-aa24-b9e39a0c9336"
      },
      "source": [
        "train_dir = '/tmp/training/'\n",
        "valid_dir = '/tmp/validation/'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Your Code Here\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Your Code Here\n",
        "validation_horses_dir = os.path.join(valid_dir, 'horses') # Your Code Here\n",
        "validation_humans_dir = os.path.join(valid_dir, 'humans') # Your Code Here\n",
        "\n",
        "train_horses_fnames = len(os.listdir(train_horses_dir)) # Your Code Here\n",
        "train_humans_fnames = len(os.listdir(train_humans_dir)) # Your Code Here\n",
        "validation_horses_fnames = len(os.listdir(validation_horses_dir)) # Your Code Here\n",
        "validation_humans_fnames = len(os.listdir(validation_humans_dir)) # Your Code Here\n",
        "\n",
        "print(train_horses_fnames)\n",
        "print(train_humans_fnames)\n",
        "print(validation_horses_fnames)\n",
        "print(validation_humans_fnames)\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7f3a502a-da94-41c8-c3e5-4c3c911a041b"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "                  rescale = 1/255.,\n",
        "                  rotation_range = 40, \n",
        "                  width_shift_range = 0.2,\n",
        "                  height_shift_range = 0.2, \n",
        "                  shear_range = 0.2, \n",
        "                  zoom_range = 0.2,\n",
        "                  horizontal_flip = True\n",
        "                )\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(\n",
        "                  rescale = 1/255.,\n",
        "                  rotation_range = 40, \n",
        "                  width_shift_range = 0.2,\n",
        "                  height_shift_range = 0.2, \n",
        "                  shear_range = 0.2, \n",
        "                  zoom_range = 0.2,\n",
        "                  horizontal_flip = True\n",
        "                 )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 20, class_mode='binary', target_size=(150, 150) )\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(valid_dir, batch_size = 20, class_mode='binary', target_size=(150, 150) )\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a2ffd21-618c-4f0c-ccb5-7e5660935ef8"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback() # Your Code Here\n",
        "history = model.fit_generator( \n",
        "      train_generator, \n",
        "      epochs = 100, \n",
        "      verbose = 2, \n",
        "      validation_data= validation_generator, \n",
        "      callbacks = [callbacks])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "52/52 - 16s - loss: 0.0449 - acc: 0.9922 - val_loss: 0.5030 - val_acc: 0.9375\n",
            "Epoch 2/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0133 - acc: 0.9951 - val_loss: 0.5608 - val_acc: 0.9414\n",
            "Epoch 3/100\n",
            "Epoch 1/100\n",
            "52/52 - 15s - loss: 0.0301 - acc: 0.9893 - val_loss: 0.5149 - val_acc: 0.9531\n",
            "Epoch 4/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0291 - acc: 0.9912 - val_loss: 1.4974 - val_acc: 0.9102\n",
            "Epoch 5/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0194 - acc: 0.9951 - val_loss: 0.6008 - val_acc: 0.9219\n",
            "Epoch 6/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0299 - acc: 0.9883 - val_loss: 1.8878 - val_acc: 0.8906\n",
            "Epoch 7/100\n",
            "Epoch 1/100\n",
            "52/52 - 15s - loss: 0.0144 - acc: 0.9922 - val_loss: 0.6634 - val_acc: 0.9297\n",
            "Epoch 8/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0123 - acc: 0.9942 - val_loss: 0.7321 - val_acc: 0.9492\n",
            "Epoch 9/100\n",
            "Epoch 1/100\n",
            "52/52 - 15s - loss: 0.0144 - acc: 0.9951 - val_loss: 0.7805 - val_acc: 0.9414\n",
            "Epoch 10/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0226 - acc: 0.9903 - val_loss: 0.6616 - val_acc: 0.9453\n",
            "Epoch 11/100\n",
            "Epoch 1/100\n",
            "52/52 - 15s - loss: 0.0209 - acc: 0.9912 - val_loss: 0.8451 - val_acc: 0.9336\n",
            "Epoch 12/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0267 - acc: 0.9912 - val_loss: 2.4834 - val_acc: 0.8789\n",
            "Epoch 13/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0271 - acc: 0.9942 - val_loss: 1.4438 - val_acc: 0.9180\n",
            "Epoch 14/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0095 - acc: 0.9971 - val_loss: 0.4933 - val_acc: 0.9570\n",
            "Epoch 15/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0108 - acc: 0.9971 - val_loss: 0.6055 - val_acc: 0.9258\n",
            "Epoch 16/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0201 - acc: 0.9932 - val_loss: 0.3062 - val_acc: 0.9688\n",
            "Epoch 17/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0179 - acc: 0.9932 - val_loss: 1.4169 - val_acc: 0.9062\n",
            "Epoch 18/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0242 - acc: 0.9942 - val_loss: 1.0663 - val_acc: 0.9258\n",
            "Epoch 19/100\n",
            "Epoch 1/100\n",
            "52/52 - 15s - loss: 0.0172 - acc: 0.9951 - val_loss: 1.0445 - val_acc: 0.9258\n",
            "Epoch 20/100\n",
            "Epoch 1/100\n",
            "52/52 - 15s - loss: 0.0158 - acc: 0.9951 - val_loss: 0.7289 - val_acc: 0.9414\n",
            "Epoch 21/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0077 - acc: 0.9961 - val_loss: 1.2009 - val_acc: 0.9258\n",
            "Epoch 22/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0180 - acc: 0.9951 - val_loss: 1.0346 - val_acc: 0.9414\n",
            "Epoch 23/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0120 - acc: 0.9961 - val_loss: 1.1231 - val_acc: 0.9297\n",
            "Epoch 24/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0130 - acc: 0.9971 - val_loss: 1.3547 - val_acc: 0.9180\n",
            "Epoch 25/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0117 - acc: 0.9961 - val_loss: 1.8782 - val_acc: 0.9023\n",
            "Epoch 26/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0348 - acc: 0.9922 - val_loss: 0.5523 - val_acc: 0.9570\n",
            "Epoch 27/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0107 - acc: 0.9981 - val_loss: 0.7444 - val_acc: 0.9492\n",
            "Epoch 28/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0079 - acc: 0.9981 - val_loss: 0.4973 - val_acc: 0.9609\n",
            "Epoch 29/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0091 - acc: 0.9951 - val_loss: 0.9257 - val_acc: 0.9297\n",
            "Epoch 30/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0132 - acc: 0.9961 - val_loss: 1.2807 - val_acc: 0.9102\n",
            "Epoch 31/100\n",
            "Epoch 1/100\n",
            "52/52 - 14s - loss: 0.0287 - acc: 0.9942 - val_loss: 1.1240 - val_acc: 0.9258\n",
            "Epoch 32/100\n",
            "Epoch 1/100\n",
            "52/52 - 15s - loss: 0.0175 - acc: 0.9932 - val_loss: 1.1884 - val_acc: 0.9141\n",
            "Epoch 33/100\n",
            "Epoch 1/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "52/52 - 15s - loss: 0.0017 - acc: 1.0000 - val_loss: 1.1251 - val_acc: 0.9180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "0c43d8e5-0f75-43eb-cf5c-3fdf52f9c515"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS1JxBr0kFWfQS1Jxb5wHFqrE9YfhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvIv6EQrY3D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}